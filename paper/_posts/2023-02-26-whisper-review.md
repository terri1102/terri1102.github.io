---
title: "Robust Speech Recognition via Large-Scale Weak Supervision ë¦¬ë·°"
published: true
future: true
date: 2023-02-25T17:20:50-04:00
tags:
    - STT
    - OpenAI
---

# [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356)
(WSPSR: Web-scale Supervised Pretraining for Speech Recognition)

> ğŸ’¡OpenAIì—ì„œ ë°œí‘œ ê°•ê±´í•œ ìŒì„±ì¸ì‹ ëª¨ë¸ë¡œ noisyí•œ ë°ì´í„°ë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•´ ë§ì€ íŠœë‹ê³¼ íœ´ë¦¬ìŠ¤í‹±ì„ ì‚¬ìš©í•œ ê²ƒì´ íŠ¹ì§•ì´ë‹¤. ê³µì‹ ì½”ë“œì™€ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì œê³µë˜ê³  ìˆìœ¼ë©° ì§€ê¸ˆê¹Œì§€ë„(2023.02.26 ê¸°ì¤€) í™œë°œíˆ ê¸°ì—¬ê°€ ì¼ì–´ë‚˜ê³  ìˆë‹¤.
<br>

# ê³µì‹ ì½”ë“œ
* [https://github.com/openai/whisper](https://github.com/openai/whisper)
* ì•„ì£¼ í›Œë¥­í•œ ì„±ëŠ¥ì˜ ìŒì„±ì¸ì‹/ìŒì„±ë²ˆì—­(ì˜ì–´) ëª¨ë¸
* ìŒì„±ì¸ì‹ì‹œ timestamp ì œê³µ



# ë…¼ë¬¸ì˜ ì˜ì˜/ê¸°ì—¬ 
1. Robust model for OOD dataset & noise 
2. Multilingual & multitask model
3. ì‹¤í—˜ ë…¼ë¬¸(Ablation)ìœ¼ë¡œì„œì˜ ê¸°ì—¬

# 1. Introduction
### Unsupervised pre-training vs. Supervised pre-training
Wav2Vec 2.0 ì˜ ë“±ì¥ ì´í›„ ìŒì„±ì¸ì‹ ë¶„ì•¼ì—ì„œëŠ” Unsupervised pretraining ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì´ ë§ì´ ë‚˜ì™”ë‹¤. í•˜ì§€ë§Œ Whisper ì €ìë“¤ì€ ìŒì„± ì¸ì‹ì€ ì–´ë–¤ ìƒí™©ì—ì„œë„ reliable í•´ì•¼ í•˜ë©°, ë§¤ ìƒí™©ì— ë”°ë¼ ë””ì½”ë”ë¥¼ fine-tuningí•  í•„ìš”ê°€ ì—†ì–´ì•¼ í•œë‹¤ëŠ” ë¬¸ì œ ì˜ì‹ì„ ê°€ì§€ê³  Supervised ëª¨ë¸ì„ ì œì•ˆí•œë‹¤.

| |Unsupervised pretrained model|Supervised pretrained model|
|---|---|---|
|ì¥ì |raw audioë¡œ í•™ìŠµí•´ ë” ì¢‹ì€ í”¼ì³ í•™ìŠµ|end-to-endë¡œ í•œ ë²ˆì— ìŒì„±ì¸ì‹ì´ ê°€ëŠ¥í•œ ëª¨ë¸ í•™ìŠµ|
| | unlabeld dataë¡œ í•™ìŠµí•´ì„œ scale upí•˜ê¸°ê°€ ì‰¬ì›€| í•™ìŠµëœ ëª¨ë¸ì„ ê°€ì ¸ë‹¤ ì‚¬ìš©í•˜ë©´ ë¨(practitioner í•„ìš” ì—†ìŒ)|
|ë‹¨ì |ì¸ì½”ë”ì²˜ëŸ¼ ê³ ì„±ëŠ¥ì„ ë‚´ëŠ” ë””ì½”ë”© ë§¤í•‘ì´ ì—†ê¸° ë•Œë¬¸ì— fine-tuning ë‹¨ê³„ë¥¼ ê±°ì³ì•¼ í•¨ â†’ fine-tuningì„ í•˜ë ¤ë©´ ì´ëŸ° ë³µì¡í•œ ê³¼ì •ì„ ì•„ëŠ” practitioner í•„ìš”|labeled dataê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— scale up í•˜ê¸° ì–´ë ¤ì›€|
| |fine-tuningí•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ì˜ íŒ¨í„´ì— ë”°ë¼ ë‹¤ë¥¸ ë°ì´í„°ì…‹ì— ì ìš©ì‹œ ì¼ë°˜í™” ì„±ëŠ¥ ë–¨ì–´ì§| |


### ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” í•´ê²° ë°©ì•ˆ
* ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ê³¼ ë„ë©”ì¸ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ê°•ê±´í•˜ê³  ì¼ë°˜í™” ì„±ëŠ¥ì´ ë†’ì€ ëª¨ë¸ ë§Œë“¤ê³ ì í•¨
* í•œê³„: Supervised datasetì€ ê·œëª¨ê°€ ì‘ìŒ (5140H - SpeechStew)
* í•´ê²°: Weakly supervised Speech recognition ë°ì´í„° ì‚¬ìš©

### weakly supervised dataset
* Noiser(low quality) training data
* Traditional supervised learningë³´ë‹¤ í° ì‚¬ì´ì¦ˆ

### ê¸°ì—¬
* weakly supervised pretrainingì„ ìŠ¤ì¼€ì¼ì—…(680,000H)
    * Supervised ëª¨ë¸ê³¼ Unsupervised ëª¨ë¸ì˜ ë°ì´í„°ì…‹ í¬ê¸° ê°„ê·¹ ì¤„ì„ (unsupervisedì˜ 100ë§Œ ì‹œê°„ vs. ê¸°ì¡´ supervisedì˜ 5140H)
* í° ëª¨ë¸ì˜ ê²½ìš° multilingual & multitask ë¡œ í•™ìŠµí•˜ëŠ” ë°ì„œ ì–»ëŠ” ì´ì  ìˆìŒ
* Fine-tuning ì—†ì´ fully-supervised modelê³¼ ë¹„ìŠ·í•œ ì„±ëŠ¥

## 2.1 Data Processing

- Pre-processingì€ ì ê²Œ í•¨
- Seperate inverse text normalizationë§Œ í•¨
- Inverse text normalization(ITN)
    * ITN: Numbers, dates, times, addresses ë“± formattingí•˜ëŠ” ì‘ì—…
    
    ![itn.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/inverse_text_normalization.png)
    

### ë°ì´í„°ì…‹ êµ¬ì¶• ğŸ’«

ì¸í„°ë„·ì—ì„œ ì°¾ì€ ì˜¤ë””ì˜¤-ëŒ€ë³¸ ìŒ ì‚¬ìš© -> í€„ë¦¬í‹°ê°€ ì¼ì •í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— automated filtering ì‚¬ìš©

  1) ASR ëª¨ë¸ì´ ë§Œë“  ëŒ€ë³¸ ì œê±°
    - ì´ë¥¼ ê°ì§€í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©
    -  ASR ê²°ê³¼ì— ì‰¼í‘œ ì—†ìŒ, ëª¨ë‘ ì†Œë¬¸ì, ë¬¸ì¥ë¶€í˜¸ë‚˜ ë‹¨ë½ êµ¬ë¶„ ìƒëµëœ ê²½ìš° ë“±

  2) ì–¸ì–´ ê°ì§€ â†’ Spoken languageì™€ ëŒ€ë³¸ì˜ ì–¸ì–´ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì œê±°

  3) ì¤‘ë³µ ë°ì´í„° ì œê±°

### Segmentation

- ì˜¤ë””ì˜¤ íŒŒì¼ì„ 30ì´ˆ ê¸¸ì´ë¡œ ìë¥¸ í›„ ê·¸ êµ¬ê°„ ë‚´ ëŒ€ë³¸ê³¼ ì—°ê²°
- Speechê°€ ì—†ëŠ” ì„¸ê·¸ë¨¼íŠ¸ëŠ” VADì— ì‚¬ìš©

### ë°ì´í„°ì…‹ í•„í„°ë§ ğŸ’«

- ëª¨ë¸ 1ì°¨ í•™ìŠµ í›„ í•™ìŠµë°ì´í„°ì˜ ì†ŒìŠ¤ì— ë”°ë¥¸ error rateë¥¼ ê³„ì‚°
- ë°ì´í„° ì†ŒìŠ¤ ì‚¬ì´ì¦ˆì™€ error rateì— ë”°ë¼ ì •ë ¬ í›„ low quality ì†ŒìŠ¤ ì œê±°
- í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°„ deduplication ì§„í–‰

## 2.2 Model Architecture

![model_architecture.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/model_architecture.png)

ëª¨ë¸ ì•„í‚¤í…ì²˜: encoder-decoder transformer


    
### Input
    
- 16,000 Hz, 80 channel log Mel Spectrogram
- 25 millisecond window with a stride of 10 milliseconds
- feature normalization: -1 ~ 1
    
### Log Mel spectrogram
    
- stft: ìŒì„± ë°ì´í„°ë¥¼ ì‹œê°„ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ FFT(ì…ë ¥ì‹ í˜¸ë¥¼ ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜ë¥¼ ê°€ì§€ëŠ” ì£¼ê¸°í•¨ìˆ˜ë¡œ ë¶„í•´)ë¥¼ í•´ì£¼ëŠ” ê²ƒ  
- ì£¼íŒŒìˆ˜ë¥¼ mel scaleë¡œ ë³€í™˜í•˜ë©´ mel filter bankê°€ ë‚˜ì˜¤ê³  stftí•œ ê²°ê³¼ì— ê³±í•´ì£¼ê³  dBë¡œ magnitudeë¥¼ ë°”ê¿”ì¤Œ
- ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ì „ì²˜ë¦¬ ë‹¨ê³„ì¸ë° waveform â†’ log-mel spectogramì„ ë½‘ê³  ì´ë¥¼ conv 1D í•„í„°ë¥¼ ì”Œìš´ í”¼ì²˜ë¥¼ ë½‘ì•„ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ì— ë„£ëŠ” ê²ƒ
    
### Encoder
1. 2 Conv layers with filter width of 3 + GELU
2. Sinusoidal position embeddingì´ output of the stemì— ì¶”ê°€
- íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ëŸ­ì€ pre-activation residual block ì‚¬ìš©
- final layer normalizationì´ ì¸ì½”ë” outputì— ì ìš©ë¨
    
### Decoder
- í•™ìŠµí•œ position embedding ì‚¬ìš© + input-output í† í° í‘œí˜„ ì‚¬ìš©
- ì¸ì½”ë”, ë””ì½”ë”ëŠ” ê°™ì€ widthì™€ íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ëŸ­ ê°œìˆ˜ ì‚¬ìš©
    
### Tokenizer    
- byte level BPE í† í¬ë‚˜ì´ì € ì‚¬ìš©(GPT2ì™€ ë™ì¼)

## 2.3 Multitask Format ğŸ’«
- ë³´í†µ ìŒì„± ëª¨ë¸ì€ ASR, VAD, SD ë“± ì—¬ëŸ¬ íƒœìŠ¤í¬ë¥¼ ë”°ë¡œ í•¨ â†’ ê·¸ëŸ¼ ì‹œìŠ¤í…œì´ ë³µì¡í•´ì§
- WhisperëŠ” í•˜ë‚˜ì˜ ëª¨ë¸ì´ ì „ì²´ íŒŒì´í”„ë¼ì¸ ë‹´ë‹¹í•¨

![multitask_training.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/multitask_training.png)

**Conditioning information:** ë””ì½”ë”ì— ë“¤ì–´ê°ˆ input tokenì„ ì»¨ë””ì…”ë‹
1. "|Start of Transcript|" í† í°ìœ¼ë¡œ ì¶”ë¡   ì‹œì‘ ë‚˜íƒ€ëƒ„
2. ì–¸ì–´ ì˜ˆì¸¡ or No Speech
3. íƒœìŠ¤í¬ ì„ íƒ: transcribe or translate
4. timestamps or No timestamps: í˜„ì¬ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ì— ìƒëŒ€ì ì¸ timeì„ ì˜ˆì¸¡í•¨
5. "|end of transcript|" í† í°ìœ¼ë¡œ ì¶”ë¡  ë ì•Œë¦¼

**Multitask:** VAD, Language identification, Transcription, Translation, timestamp prediction

## 2.4 Training Details
- ë‹¤ì–‘í•œ ì‚¬ì´ì¦ˆì˜ ëª¨ë¸ í•™ìŠµ
- í•™ìŠµ í™˜ê²½
    - data parallelism across accelerators
    - using FP16
    - with dynamic loss scaling
    - activation check point
- í•™ìŠµ ì „ëµ
    - AdamW
    - gradient norm clipping
    - linear learning rate decay to zero
    - warm up over the first 2048 updates
    - batch size of 256 segments
    - $2^20$ updates (2-3 passes over the dataset)
    - data augmentation ì´ë‚˜ regularization ì•ˆ í•¨

Whisperì˜ ì´ìƒ í–‰ë™

- ì´ˆê¸° ë‹¨ê³„ì—ì„œ í™”ì ì´ë¦„ì„ ê·¸ëŸ´ë“¯í•œ í‹€ë¦° ì´ë¦„ìœ¼ë¡œ ì˜ˆì¸¡í•¨
- ì›ì¸: ëŒ€ë³¸ì— í™”ì ì´ë¦„ ìˆëŠ” ë°ì´í„°ì…‹ ë•Œë¬¸
- í•´ê²°: í™”ì ì´ë¦„ì´ ì•ˆ ë‚˜ì˜¤ëŠ” ì¼ë¶€ ëŒ€ë³¸ì— ì ê¹ fine-tuningí•¨

# 3. Experiments

### Zero-shot evaluation

- ì¶”ê°€í•™ìŠµ ì—†ì´ ë‹¤ì–‘í•œ ë„ë©”ì¸, íƒœìŠ¤í¬, ì–¸ì–´ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸
- ì—¬ëŸ¬ ë°ì´í„°ì…‹ì˜ test datasetìœ¼ë¡œë§Œ í…ŒìŠ¤íŠ¸

### Evaluation Metrics

**WER(word error rate)** 

- WER = (S+D+I)/N
    - D: ì˜ëª» ì‚­ì œëœ ë‹¨ì–´ ìˆ˜, S: ì˜ëª» ëŒ€ì²´ëœ ë‹¨ì–´ ìˆ˜, I: ì˜ëª» ì¶”ê°€ëœ ë‹¨ì–´ ìˆ˜, N: ì •ë‹µ í…ìŠ¤íŠ¸ì˜ ë‹¨ì–´ ìˆ˜
- WERì€ string edit distanceë¥¼ êµ¬í•˜ëŠ”ë° ëª¨ë¸ outputì˜ ëª¨ë“  ì°¨ì´ë¥¼ penalizeí•¨ (ëŒ€ë³¸ì“°ëŠ” ìŠ¤íƒ€ì¼ì´ ë‹¤ë¥¸ ê²ƒì„ì—ë„ formatì°¨ì´ë¡œ ë†’ì€ error rate ë‚˜ì˜¬ ìˆ˜ ìˆìŒ)
- ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ text normalizer ì‚¬ìš©í•¨
- text normalizer ì‚¬ìš©ìœ¼ë¡œ WER ê±°ì˜ 50% ê°ì†Œí•¨

### Task-specific results

- English Speech Recognition
    - In-the-distribution: ì‚¬ëŒë³´ë‹¤ AIê°€ ì˜ í•¨
    - Out-of-distribution: ì‚¬ëŒë³´ë‹¤ AIê°€ ëª» í•¨
    - ì›ì¸
        - AI: í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ë°ì´í„°ì˜ distribution ë¹„ìŠ·(test setì„ ê°™ì€ ë°ì´í„°ì…‹ ë‚´ì—ì„œ held out ë°©ì‹ìœ¼ë¡œ ë§Œë“œë‹ˆê¹Œ)
        - ì¸ê°„: zero-shot test
    - WhisperëŠ” ì´ë¥¼ ê·¹ë³µí•˜ê³ ì í•¨: ë‹¤ì–‘í•œ ë°ì´í„°ì…‹/distributionìœ¼ë¡œ í•™ìŠµ
    
**ì„±ëŠ¥ ë¹„êµ**

![result.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/result.png)
    
- Multi-lingual Speech Recognition
    - Indo-European vs. others: ë°ì´í„°ì…‹ì˜ ëŒ€ë¶€ë¶„ì´ Indo-European ë°ì´í„°ì´ê¸° ë•Œë¬¸ì— Indo-European ì–¸ì–´ì˜ ì„±ëŠ¥ì´ ë” ë†’ìŒ
        
- Translation
    - BLEUë¡œ ì¸¡ì •
    - Welsh ë°ì´í„° ë¼ë²¨ë§ ì˜ëª»ë˜ì–´ ìˆë˜ ì‚¬ë¡€ ê³µìœ  - ì¸í„°ë„·ì—ì„œ ê¸ì—ˆê¸° ë•Œë¬¸ì— ìˆì„ ìˆ˜ ìˆëŠ” ì¼
    
    - ê·¸ë˜í”„
        
        ![bleu.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/bleu.png)
        

- Language Identification
    Fleursë¡œ í…ŒìŠ¤íŠ¸í–ˆëŠ”ë° ë‹¤ë¥¸ SOTAì— ë¹„í•´ ì ìˆ˜ ë§ì´ ë‚®ìŒ<br>
    ì´ìœ : Fleursì˜ 102ê°œ ì–¸ì–´ ì¤‘ 20 ì–¸ì–´ê°€ í•™ìŠµì…‹ì— í¬í•¨ ì•ˆ ë¨
    

### Robustness to Additive Noise
- ë°ì´í„°ì— ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•´ì„œ ì„±ëŠ¥ í‰ê°€í•¨
- white noise & pub noise
- ë…¸ì´ì¦ˆê°€ ê°•í•´ì§ˆìˆ˜ë¡ Whisperê°€ ë‹¤ë¥¸ ëª¨ë¸ë³´ë‹¤ ê°•ê±´í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¨
    
    ![robustness.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/robustness_to_noise.png)
    

### Long-form Transcription
* 30ì´ˆë¡œ ì˜ë¼ì„œ í•™ìŠµí–ˆê¸° ë•Œë¬¸ì— í•œ ë²ˆì— ê¸´ inputì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŒ
â†’ 30ì´ˆë¡œ ì˜ë¼ì„œ ì¶”ë¡ 
* beam search + temperature schedulingì´ ì„±ëŠ¥ í–¥ìƒì— ì¤‘ìš”

![long-form_transcription.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/long_form_transcription.png)

### Comparison with Human Performance

í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¼ë¶€ ë°ì´í„°(Kincaid46 dataset) ì„ ì •í•´ì„œ í‰ê°€í•´ë³¸ ê²°ê³¼ WhisperëŠ” ì‚¬ëŒê³¼ ë¹„ìŠ·í•œ ìˆ˜ì¤€

![comparison_with_human.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/comparison_with_human_performance.png)

# 4. Analysis and Ablations

### Model Scaling
- Weakly supervised model ì´ë‹¤ë³´ë‹ˆê¹Œ ë” í° ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê³  noiserí•œ ë°ì´í„°
- saturation ë¬¸ì œ
- ë°ì´í„°ì…‹ì˜ ê°œì„±ì„ ë°°ìš°ê³  ì¼ë°˜í™” ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ
- ëª¨ë¸ ì‚¬ì´ì¦ˆë¡œ í…ŒìŠ¤íŠ¸í•´ë³¸ ê²°ê³¼ ì˜ì–´ ì œì™¸í•˜ê³  ëª¨ë¸ ì‚¬ì´ì¦ˆ ëŠ˜ë¦´ìˆ˜ë¡ ì„±ëŠ¥ ê³„ì† ì˜¬ë¼ê°

### Dataset Scaling
- ëª¨ë“  íƒœìŠ¤í¬ì—ì„œ ë°ì´í„°ì…‹ ì‚¬ì´ì¦ˆëŠ” ì„±ëŠ¥ê³¼ ë¹„ë¡€í•¨
- whisper ëª¨ë¸ë„ under trained ë˜ì—ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆì–´ì„œ ë” í° ëª¨ë¸ê³¼ ë” ì˜¤ëœ í•™ìŠµìœ¼ë¡œ ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥í•  ìˆ˜ ìˆìŒ

### Multitask and Multilingual Transfer
- í•˜ë‚˜ì˜ ëª¨ë¸ì„ multitask, multilingualë¡œ í•™ìŠµí•  ë•Œ negative transfer ë¬¸ì œ ìˆì„ ìˆ˜ ìˆìŒ
- ì‘ì€ ëª¨ë¸ì˜ ê²½ìš°: negative transfer ìˆìŒ
    - joint model < english only model
- í° ëª¨ë¸ì˜ ê²½ìš°: multitask, multilingual ëª¨ë¸ì´ ì„±ëŠ¥ ë” ì¢‹ì•˜ìŒ

### Text Normalization ğŸ’«
- Whisperì— ì‚¬ìš©í•œ text normalizerê°€ whisperì— overfitë˜ì—ˆë‚˜ í…ŒìŠ¤íŠ¸
- Whisperê³¼ ê°™ì´ text normailizationì„ ê°œë°œí–ˆê¸° ë•Œë¬¸ì— whisperì˜ ê³¼ì í•©ë˜ì—ˆì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€
- Fairspeechì˜ normalizerì™€ ë¹„êµí•¨
- text normalizer ë¹„êµ
    
    ![text_normalizer.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/text_normalizer.png)
    
- 13ê°œì˜ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë¹„êµí•´ë´¤ì„ ë•Œ ìˆ˜ì¹˜ê°€ ë§ì´ ë‚˜ì˜¤ëŠ” ë°ì´í„°ì…‹ì˜ ê²½ìš° Whisperì„ ì´ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ë” ì¢‹ì•˜ìŒ

### Strategies for Reliable Long-form Transcription ğŸ’«
* ê¸´ ëŒ€ë³¸ì„ ì¶”ë¡ í•˜ê¸° ìœ„í•´ ì¶”ê°€í•œ íœ´ë¦¬ìŠ¤í‹±í•œ íŠœë‹ë“¤
    - Beam search w/ 5 beams and log probability as the score function
    - Start from temperature 0 â†’ increase by 0.2 to 1.0
    - VAD ê°œì„ ì„ ìœ„í•´ |No Speech| í† í° ë¿ ì•„ë‹ˆë¼ no-speech probabilityê°€ 0.6 ì´ìƒì¸ ê²½ìš°ë„ í•„í„°ë§
    - ëª¨ë¸ì´ ì´ˆê¸° ë‹¨ì–´ ë¬´ì‹œí•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì²« timestampëŠ” 0.0~1.0ì´ˆ ì‚¬ì´ë¡œ ì œí•œ
    - Beam search<br>
    Beam search: beam width ë§Œí¼ì˜ í† í°ì„ inputìœ¼ë¡œ ë„£ê³  softmax output layerë¥¼ ê±°ì³ì„œ beam ê°œìˆ˜ë§Œí¼ì˜ í† í°ì„ ì˜ˆì¸¡í•¨. ì´ë ‡ê²Œ ë‚˜ì˜¨ í›„ë³´ë“¤ ì¤‘ ê°€ì¥ í™•ë¥  ë†’ì€ ì‹œí€€ìŠ¤ ì„ íƒ
    
    ![beam_search.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/beam_search.png)
    

# 5. Related Work
- Scaling Speech Recognition
- Multitask Learning
- Robustness

# 6. Limitations and Future Work
### Improved decoding strategies
- Perception related error(ë¹„ìŠ·í•œ ì†Œë¦¬ êµ¬ë¶„) â†’ ëª¨ë¸ í¬ê¸° í‚¤ìš°ë©´ ê°œì„  ê°€ëŠ¥
- í•˜ì§€ë§Œ non-perceptual errorì˜ í•´ê²°ì€ ì•„ì§ ìˆ™ì œì„
- ì´ëŸ° ì—ëŸ¬ë“¤ì€ ì–¸ì–´ ëª¨ë¸ ìì²´ì˜ ë¬¸ì œ ë•Œë¬¸ì¸ë° complete hallucinationì´ë‚˜ stuck in repeat loops, ì²« ë‹¨ì–´ë‚˜ ë§ˆì§€ë§‰ ë‹¨ì–´ë¥¼ ì „ì‚¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì œ ë“±
- í•´ê²° ë°©ì•ˆ ì œì•ˆ: ê³ í’ˆì§ˆì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ê±°ë‚˜ ê°•í™”í•™ìŠµìœ¼ë¡œ ë””ì½”ë”© ê°œì„ 

### Increase Training data for lower-resource languages
- ë°ì´í„°ì…‹ì´ ëŒ€ë¶€ë¶„ ì˜ì–´ë¡œ ì´ë£¨ì–´ì ¸ ìˆê¸° ë•Œë¬¸ì— ë°ì´í„° ë¶ˆê· í˜•ì´ ì‹¬í•¨
- ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ì–¸ì–´ì˜ ê²½ìš° ë°ì´í„° ì¶”ê°€í•˜ëŠ” ê²ƒì´ ë‹¹ì—°íˆ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë¨

### Studying fine-tuning
- ê³ í’ˆì§ˆì˜ supervised speech dataê°€ ì¡´ì¬í•˜ë©´ fine-tuningí–ˆì„ ë•Œ ì„±ëŠ¥ì´ ë” ì˜¬ë¼ê°ˆ ê²ƒ

### Tuning Architecture, Regularization, and Augmentation
- ì´ ë…¼ë¬¸ì—ì„œ ì£¼ë ¥í•˜ê³ ì í•œ ê²ƒì´ ë°ì´í„°ì…‹ scale upì´ì—ˆê¸° ë•Œë¬¸ì— ì´ì— ì§‘ì¤‘í•˜ê³ ì ìµœì‹  ê¸°ë²•ë“¤ì´ ë§ì´ ì‚¬ìš©ë˜ì§€ëŠ” ì•Šì•˜ìŒ
- dropout, stochastic depth, data augmentation, SpecAugment ë“±ì˜ ê¸°ë²•ê³¼ fine-tuningìœ¼ë¡œ ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥

### Adding Auxiliary Training Objectives
- ìµœì‹  ì—°êµ¬ì˜ íë¦„ì¸ unsupervised pre-trainingì´ë‚˜ self-teaching ê¸°ë²•ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì§€ë§Œ ì´ë¥¼ ì˜ ê²°í•©í•˜ë©´ ì„±ëŠ¥ ê°œì„ ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŒ

# 7. Conclusion
ë‹¨ìˆœí•œ ë°©ë²•ì´ì§€ë§Œ ë” í¬ê³  **ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµ**í•˜ëŠ” ê²ƒê³¼ **zero-shot transfer**ì´ ëª¨ë¸ì˜ ê°•ê±´í•¨ì„ ê°œì„ í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤Œ


# í•œêµ­ì–´ ì„±ëŠ¥
- Fleurs ë°ì´í„°ì…‹ ì–¸ì–´ë³„ ì„±ëŠ¥
    
    ![fleurs.png](https://raw.githubusercontent.com/terri1102/blog_images/main/papers/2023-02-26-whisper/fleurs_dataset.png)

# ì½ì€ í›„ê¸°
ë‹¤ì–‘í•œ ì‹¤í—˜ ê²°ê³¼ì™€ ì „ì²˜ë¦¬ ê³¼ì •ì— ëŒ€í•œ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•˜ê³  ìˆëŠ” ë…¼ë¬¸ì´ì–´ì„œ ìŒì„± ì¸ì‹ ëª¨ë¸ì„ ë§Œë“¤ ë•Œ ë§ì€ ë„ì›€ì„ ë°›ì•˜ë‹¤. ì‹œê°„ ë° ì¸ë ¥ ìì›ì˜ ë¶€ì¡±ìœ¼ë¡œ ë§ì€ íŠœë‹ì„ í•´ë³´ê¸° ì–´ë ¤ìš´ë° ìœ„ ë…¼ë¬¸ì„ ì°¸ê³ í•´ì„œ ê³µë¶€í•˜ê³  ë•Œë•Œë¡œ í•„ìš”í•œ ë¶€ë¶„ì„ ì ìš©í•˜ê³  ìˆë‹¤. ë˜í•œ ì¢‹ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ì™€ ì½”ë“œê°€ ê³µìœ ë˜ì–´ ìˆì–´ ì‚¬ìš©ì´ ì‰½ê³  í•œêµ­ì–´ ì˜ˆì‹œê°€ ë§ì´ ìˆì–´ì„œ ë‚´ì  ì¹œë°€ê°ì„ ëŠë¼ê¸° ì¢‹ë‹¤.


# Reference
* [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356)
* [https://github.com/openai/whisper](https://github.com/openai/whisper)
* [https://machinelearning.apple.com/research/inverse-text-normal](https://machinelearning.apple.com/research/inverse-text-normal)
* [https://velog.io/@p2yeong/ì˜¤ë””ì˜¤-ì²˜ë¦¬Audio-Processing](https://velog.io/@p2yeong/%EC%98%A4%EB%94%94%EC%98%A4-%EC%B2%98%EB%A6%ACAudio-Processing)
* [https://huggingface.co/datasets/google/fleurs](https://huggingface.co/datasets/google/fleurs)
* [https://openai.com/blog/whisper/](https://openai.com/blog/whisper/)